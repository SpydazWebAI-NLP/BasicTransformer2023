Public Class TransformerModel ' Transformer model configuration Private EmbeddingSize As Integer Private NumEncoderLayers As Integer Private NumDecoderLayers As Integer Private NumHeads As Integer Private SelfAttentionDim As Integer Private FeedForwardDim As Integer Private Epsilon As Double Private Beta1 As Double Private Beta2 As Double Private LearningRate As Double Private NumEpochs As Integer
    Private EncoderLayers As List(Of TransformerLayer)
    Private DecoderLayers As List(Of TransformerLayer)
    Private WordEmbeddings As Embeddings.Factory.WordEmbeddingsModel
    Private EmbeddingSize As Integer
    Private NumEncoderLayers As Integer
    Private NumDecoderLayers As Integer
    Private NumHeads As Integer
    Private SelfAttentionDim As Integer
    Private FeedForwardDim As Integer
    Private Epsilon As Double
    Private Beta1 As Double
    Private Beta2 As Double
    Private LearningRate As Double
    Private NumEpochs As Integer
    Private ReadOnly m_dict As New Dictionary(Of String, Double())
    Private ReadOnly v_dict As New Dictionary(Of String, Double())
    Public Class TransformerLayer
        Public Property EmbeddingSize As Integer
        Public Property SelfAttentionDim As Integer
        Public Property FeedForwardDim As Integer
        Public Property Epsilon As Double
        Public Property NumHeads As Integer
        Public Property SelfAttentionMask As Double()
        Public Property EncoderDecoderAttentionMask As Double()

        Public Sub New(embeddingSize As Integer, selfAttentionDim As Integer, feedForwardDim As Integer,
                   epsilon As Double, numHeads As Integer)
            Me.EmbeddingSize = embeddingSize
            Me.SelfAttentionDim = selfAttentionDim
            Me.FeedForwardDim = feedForwardDim
            Me.Epsilon = epsilon
            Me.NumHeads = numHeads

            ' Initialize self-attention mask and encoder-decoder attention mask
            ' ... Implement the mask initialization as needed ...
        End Sub
        Private Sub LayerNormalize(ByRef vector As Double())
            ' Compute the mean and variance of the vector.
            Dim mean As Double = vector.Average()
            Dim variance As Double = vector.Select(Function(x) (x - mean) * (x - mean)).Average()

            ' Normalize the vector.
            For i As Integer = 0 To vector.Length - 1
                vector(i) = (vector(i) - mean) / Math.Sqrt(variance + Epsilon)
            Next
        End Sub
        Private Sub AddAndNorm(ByRef decoderOutput As List(Of Double()), ByRef sourceEmbeddings As List(Of Double()))
            ' Add the output of the decoder and the source embeddings.
            For i As Integer = 0 To decoderOutput.Count - 1
                For j As Integer = 0 To decoderOutput(i).Length - 1
                    decoderOutput(i)(j) += sourceEmbeddings(i)(j)
                Next
            Next

            ' Apply layer normalization to the combined output.
            For i As Integer = 0 To decoderOutput.Count - 1
                LayerNormalize(decoderOutput(i))
            Next
        End Sub
    End Class

    Public Sub New(embeddingSize As Integer, numEncoderLayers As Integer, numDecoderLayers As Integer,
                   numHeads As Integer, selfAttentionDim As Integer, feedForwardDim As Integer,
                   epsilon As Double, beta1 As Double, beta2 As Double, learningRate As Double, numEpochs As Integer,
                   vocabulary As List(Of String))
        Me.EmbeddingSize = embeddingSize
        Me.NumEncoderLayers = numEncoderLayers
        Me.NumDecoderLayers = numDecoderLayers
        Me.NumHeads = numHeads
        Me.SelfAttentionDim = selfAttentionDim
        Me.FeedForwardDim = feedForwardDim
        Me.Epsilon = epsilon
        Me.Beta1 = beta1
        Me.Beta2 = beta2
        Me.LearningRate = learningRate
        Me.NumEpochs = numEpochs

        ' Initialize the word embeddings model
        WordEmbeddings = New Embeddings.Factory.HybridWordEmbeddingsModel(vocabulary)

        ' Initialize encoder and decoder layers
        EncoderLayers = New List(Of TransformerLayer)()
        For i As Integer = 0 To numEncoderLayers - 1
            EncoderLayers.Add(New TransformerLayer(embeddingSize, selfAttentionDim, feedForwardDim, epsilon, numHeads))
        Next

        DecoderLayers = New List(Of TransformerLayer)()
        For i As Integer = 0 To numDecoderLayers - 1
            DecoderLayers.Add(New TransformerLayer(embeddingSize, selfAttentionDim, feedForwardDim, epsilon, numHeads))
        Next
    End Sub

    ' Layer normalization function
    Private Function LayerNormalization(x As Double()(), epsilon As Double) As Double()()
        Dim numInputs As Integer = x(0).Length
        Dim numSamples As Integer = x.Length
        ' Calculate the mean and variance
        Dim mean As Double() = New Double(numInputs - 1) {}
        Dim variance As Double() = New Double(numInputs - 1) {}

        For i As Integer = 0 To numInputs - 1
            Dim sum As Double = 0
            For j As Integer = 0 To numSamples - 1
                sum += x(j)(i)
            Next
            mean(i) = sum / numSamples

            Dim squaredSum As Double = 0
            For j As Integer = 0 To numSamples - 1
                squaredSum += (x(j)(i) - mean(i)) * (x(j)(i) - mean(i))
            Next
            variance(i) = squaredSum / numSamples
        Next

        ' Normalize the inputs
        Dim normalizedX As Double()() = New Double(numSamples - 1)() {}
        For i As Integer = 0 To numSamples - 1
            normalizedX(i) = New Double(numInputs - 1) {}
            For j As Integer = 0 To numInputs - 1
                normalizedX(i)(j) = (x(i)(j) - mean(j)) / Math.Sqrt(variance(j) + epsilon)
            Next
        Next

        Return normalizedX
    End Function
    Private Function AddResidual(x As Double()(), residual As Double()()) As Double()()
        Dim numInputs As Integer = x(0).Length
        Dim numSamples As Integer = x.Length
        Dim result As Double()() = New Double(numSamples - 1)() {}
        For i As Integer = 0 To numSamples - 1
            result(i) = New Double(numInputs - 1) {}
            For j As Integer = 0 To numInputs - 1
                result(i)(j) = x(i)(j) + residual(i)(j)
            Next
        Next

        Return result
    End Function
    ' Positional encoding function
    Private Function GetPositionalEncoding(inputLength As Integer, dimModel As Integer) As Double()()
        Dim positionalEncoding As Double()() = New Double(inputLength - 1)() {}
        For i As Integer = 0 To inputLength - 1
            positionalEncoding(i) = New Double(dimModel - 1) {}
            For j As Integer = 0 To dimModel - 1
                If j Mod 2 = 0 Then
                    positionalEncoding(i)(j) = Math.Sin(i / Math.Pow(10000, j / dimModel))

                Else positionalEncoding(i)(j) = Math.Cos(i / Math.Pow(10000, (j - 1) / dimModel))
                End If
            Next
        Next
        Return positionalEncoding
    End Function

    'Masking Function for the decoder self-attention 
    Private Function MaskSelfAttention(inputs As Double()(), maskValue As Double) As Double()()
        Dim numSamples As Integer = inputs.Length
        Dim numSteps As Integer = inputs(0).Length
        Dim maskedInputs As Double()() = New Double(numSamples - 1)() {}
        For i As Integer = 0 To numSamples - 1
            maskedInputs(i) = New Double(numSteps - 1) {}
            For j As Integer = 0 To numSteps - 1
                If j < i Then
                    maskedInputs(i)(j) = maskValue
                Else
                    maskedInputs(i)(j) = inputs(i)(j)
                End If
            Next
        Next

        Return maskedInputs
    End Function

    Private Function ConvertToNumericData(ByRef inputText As List(Of List(Of String)), ByRef vocab As Dictionary(Of String, Integer)) As List(Of List(Of Integer))
        Dim numericData As New List(Of List(Of Integer))

        For Each sentence In inputText
            Dim numericSentence As New List(Of Integer)
            For Each word In sentence
                If vocab.ContainsKey(word) Then
                    numericSentence.Add(vocab(word))
                Else
                    numericSentence.Add(vocab("<UNK>")) ' Replace unknown words with the <UNK> token.
                End If
            Next
            numericData.Add(numericSentence)
        Next

        Return numericData
    End Function

End Class
Public Class Encoder
    Private ReadOnly NumLayers As Integer
    Private ReadOnly Layers As List(Of EncoderLayer)

    Public Sub New(NumLayers As Integer, DimModel As Integer, NumHeads As Integer, DimFeedForward As Integer, DropoutRate As Double)
        Me.NumLayers = NumLayers
        Layers = New List(Of EncoderLayer)()

        For i As Integer = 0 To NumLayers - 1
            Layers.Add(New EncoderLayer(DimModel, NumHeads, DimFeedForward, DropoutRate))
        Next
    End Sub


End Class
Public Class EncoderLayer
    Private ReadOnly DimModel As Integer
    Private ReadOnly NumHeads As Integer
    Private ReadOnly DimFeedForward As Integer
    Private ReadOnly DropoutRate As Double

    Private MultiHeadAttentionLayer As TransformerEncoderDecoder.TransformerEncoder.MultiHeadAttention
    Private FeedForwardNetwork As TransformerEncoderDecoder.TransformerEncoder.FeedForwardNetwork

    Public Sub New(DimModel As Integer, NumHeads As Integer, DimFeedForward As Integer, DropoutRate As Double)
        Me.DimModel = DimModel
        Me.NumHeads = NumHeads
        Me.DimFeedForward = DimFeedForward
        Me.DropoutRate = DropoutRate

        MultiHeadAttentionLayer = New TransformerEncoderDecoder.TransformerEncoder.MultiHeadAttention(NumHeads, DimModel)
        FeedForwardNetwork = New TransformerEncoderDecoder.TransformerEncoder.FeedForwardNetwork(DimModel, DimFeedForward)
    End Sub



End Class
Public Class Decoder
    Private ReadOnly NumLayers As Integer
    Private ReadOnly Layers As List(Of DecoderLayer)

    Public Sub New(NumLayers As Integer, DimModel As Integer, NumHeads As Integer, DimFeedForward As Integer, DropoutRate As Double)
        Me.NumLayers = NumLayers
        Layers = New List(Of DecoderLayer)()

        For i As Integer = 0 To NumLayers - 1
            Layers.Add(New DecoderLayer(DimModel, NumHeads, DimFeedForward, DropoutRate))
        Next
    End Sub


End Class
Public Class DecoderLayer
    Private ReadOnly DimModel As Integer
    Private ReadOnly NumHeads As Integer
    Private ReadOnly DimFeedForward As Integer
    Private ReadOnly DropoutRate As Double

    Private MultiHeadAttentionLayer As TransformerEncoderDecoder.TransformerEncoder.MultiHeadAttention
    Private EncoderDecoderAttentionLayer As TransformerEncoderDecoder.TransformerEncoder.MultiHeadAttention
    Private FeedForwardNetwork As TransformerEncoderDecoder.TransformerEncoder.FeedForwardNetwork

    Public Sub New(DimModel As Integer, NumHeads As Integer, DimFeedForward As Integer, DropoutRate As Double)
        Me.DimModel = DimModel
        Me.NumHeads = NumHeads
        Me.DimFeedForward = DimFeedForward
        Me.DropoutRate = DropoutRate

        MultiHeadAttentionLayer = New TransformerEncoderDecoder.TransformerEncoder.MultiHeadAttention(NumHeads, DimModel)
        EncoderDecoderAttentionLayer = New TransformerEncoderDecoder.TransformerEncoder.MultiHeadAttention(NumHeads, DimModel)
        FeedForwardNetwork = New TransformerEncoderDecoder.TransformerEncoder.FeedForwardNetwork(DimModel, DimFeedForward)
    End Sub



End Class